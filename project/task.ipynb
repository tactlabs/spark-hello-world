{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_df: org.apache.spark.sql.DataFrame = [_c0: string, Player Name: string ... 6 more fields]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val source_df = spark.read.option(\"header\", \"true\").option(\"multiLine\", \"true\").csv(\"file:/home/nagulraj/tact/datasets/Player_information.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------------------+-------------+---------------------+-----------------+------+--------+\n",
      "|_c0|         Player Name|     Team of Player|National Team|International matches|    Born_date/Age|Height|   Value|\n",
      "+---+--------------------+-------------------+-------------+---------------------+-----------------+------+--------+\n",
      "|  0|       Kylian Mbappé|Paris Saint-Germain|       France|                 null|Dec 20, 1998 (23)|  1,78|€160.00m|\n",
      "|  1|      Erling Haaland|  Borussia Dortmund|       Norway|                   15|Jul 21, 2000 (21)|  1,94|€150.00m|\n",
      "|  2|     Vinicius Junior|        Real Madrid|       Brazil|                   11|Jul 12, 2000 (21)|  1,76|€100.00m|\n",
      "|  3|       Mohamed Salah|       Liverpool FC|        Egypt|                   80|Jun 15, 1992 (29)|  1,75|€100.00m|\n",
      "|  4|          Harry Kane|  Tottenham Hotspur|      England|                   67|Jul 28, 1993 (28)|  1,88|€100.00m|\n",
      "|  5|       Romelu Lukaku|         Chelsea FC|      Belgium|                 null|May 13, 1993 (28)|  1,91|€100.00m|\n",
      "|  6|     Bruno Fernandes|  Manchester United|     Portugal|                   40| Sep 8, 1994 (27)|  1,79| €90.00m|\n",
      "|  7|     Kevin De Bruyne|    Manchester City|      Belgium|                   88|Jun 28, 1991 (30)|  1,81| €90.00m|\n",
      "|  8|              Neymar|Paris Saint-Germain|       Brazil|                  116| Feb 5, 1992 (30)|  1,75| €90.00m|\n",
      "|  9|          Phil Foden|    Manchester City|      England|                   13|May 28, 2000 (21)|  1,71| €85.00m|\n",
      "| 10|        Jadon Sancho|  Manchester United|      England|                   23|Mar 25, 2000 (21)|  1,80| €85.00m|\n",
      "| 11|     Marcus Rashford|  Manchester United|      England|                   46|Oct 31, 1997 (24)|  1,85| €85.00m|\n",
      "| 12|      Joshua Kimmich|      Bayern Munich|      Germany|                   64| Feb 8, 1995 (27)|  1,77| €85.00m|\n",
      "| 13|     Raheem Sterling|    Manchester City|      England|                   72| Dec 8, 1994 (27)|  1,70| €85.00m|\n",
      "| 14|               Pedri|       FC Barcelona|        Spain|                   10|Nov 25, 2002 (19)|  1,74| €80.00m|\n",
      "| 15|    Lautaro Martínez|        Inter Milan|    Argentina|                   37|Aug 22, 1997 (24)|  1,74| €80.00m|\n",
      "| 16|Trent Alexander-A...|       Liverpool FC|      England|                   16| Oct 7, 1998 (23)|  1,80| €80.00m|\n",
      "| 17|       Jack Grealish|    Manchester City|      England|                   18|Sep 10, 1995 (26)|  1,80| €80.00m|\n",
      "| 18|          Sadio Mané|       Liverpool FC|      Senegal|                   86|Apr 10, 1992 (29)|  1,74| €80.00m|\n",
      "| 19|       Heung-min Son|  Tottenham Hotspur|  South Korea|                   98| Jul 8, 1992 (29)|  1,84| €80.00m|\n",
      "+---+--------------------+-------------------+-------------+---------------------+-----------------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source_df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df1: org.apache.spark.sql.DataFrame = [National Team: string]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df1 = source_df.select(\"National Team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|National Team|\n",
      "+-------------+\n",
      "|       France|\n",
      "|       Norway|\n",
      "|       Brazil|\n",
      "|        Egypt|\n",
      "|      England|\n",
      "|      Belgium|\n",
      "|     Portugal|\n",
      "|      Belgium|\n",
      "|       Brazil|\n",
      "|      England|\n",
      "|      England|\n",
      "|      England|\n",
      "|      Germany|\n",
      "|      England|\n",
      "|        Spain|\n",
      "|    Argentina|\n",
      "|      England|\n",
      "|      England|\n",
      "|      Senegal|\n",
      "|  South Korea|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df2: org.apache.spark.sql.DataFrame = [Team of Player: string]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = source_df.select(\"Team of Player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "merged_df: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Team of Player: string]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val merged_df = df2.union(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mergedf1: org.apache.spark.sql.DataFrame = [Team of Player: string, National Team: string]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mergedf1= df2.join(df1)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+\n",
      "|     Team of Player|National Team|\n",
      "+-------------------+-------------+\n",
      "|Paris Saint-Germain|       France|\n",
      "|Paris Saint-Germain|       Norway|\n",
      "|Paris Saint-Germain|       Brazil|\n",
      "|Paris Saint-Germain|        Egypt|\n",
      "|Paris Saint-Germain|      England|\n",
      "|Paris Saint-Germain|      Belgium|\n",
      "|Paris Saint-Germain|     Portugal|\n",
      "|Paris Saint-Germain|      Belgium|\n",
      "|Paris Saint-Germain|       Brazil|\n",
      "|Paris Saint-Germain|      England|\n",
      "|Paris Saint-Germain|      England|\n",
      "|Paris Saint-Germain|      England|\n",
      "|Paris Saint-Germain|      Germany|\n",
      "|Paris Saint-Germain|      England|\n",
      "|Paris Saint-Germain|        Spain|\n",
      "|Paris Saint-Germain|    Argentina|\n",
      "|Paris Saint-Germain|      England|\n",
      "|Paris Saint-Germain|      England|\n",
      "|Paris Saint-Germain|      Senegal|\n",
      "|Paris Saint-Germain|  South Korea|\n",
      "+-------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mergedf1.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|     Team of Player|\n",
      "+-------------------+\n",
      "|Paris Saint-Germain|\n",
      "|  Borussia Dortmund|\n",
      "|        Real Madrid|\n",
      "|       Liverpool FC|\n",
      "|  Tottenham Hotspur|\n",
      "|         Chelsea FC|\n",
      "|  Manchester United|\n",
      "|    Manchester City|\n",
      "|Paris Saint-Germain|\n",
      "|    Manchester City|\n",
      "|  Manchester United|\n",
      "|  Manchester United|\n",
      "|      Bayern Munich|\n",
      "|    Manchester City|\n",
      "|       FC Barcelona|\n",
      "|        Inter Milan|\n",
      "|       Liverpool FC|\n",
      "|    Manchester City|\n",
      "|       Liverpool FC|\n",
      "|  Tottenham Hotspur|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_df1: org.apache.spark.sql.DataFrame = [_c0: string, Player Name: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " val source_df1 = source_df.drop(col(\"Born_date/Age\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "23: error: not found: value source_df1",
     "output_type": "error",
     "traceback": [
      "<console>:23: error: not found: value source_df1",
      "       val dfAverage = source_df1.agg(avg(source_df1(\"International matches\").cast(\"int\")).as(\"average\"))",
      "                       ^",
      "<console>:23: error: not found: value source_df1",
      "       val dfAverage = source_df1.agg(avg(source_df1(\"International matches\").cast(\"int\")).as(\"average\"))",
      "                                          ^",
      ""
     ]
    }
   ],
   "source": [
    "val dfAverage = source_df1.agg(avg(source_df1(\"International matches\").cast(\"int\")).as(\"average\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|           average|\n",
      "+------------------+\n",
      "|27.890080428954423|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfAverage.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avrg: Double = 27.890080428954423\n"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val avrg=dfAverage.first.getDouble(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfnull: org.apache.spark.sql.DataFrame = [International matches: string]\n"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val dfnull = source_df.select(\"International matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|International matches|\n",
      "+---------------------+\n",
      "|                 null|\n",
      "|                   15|\n",
      "|                   11|\n",
      "|                   80|\n",
      "|                   67|\n",
      "|                 null|\n",
      "|                   40|\n",
      "|                   88|\n",
      "|                  116|\n",
      "|                   13|\n",
      "|                   23|\n",
      "|                   46|\n",
      "|                   64|\n",
      "|                   72|\n",
      "|                   10|\n",
      "|                   37|\n",
      "|                   16|\n",
      "|                   18|\n",
      "|                   86|\n",
      "|                   98|\n",
      "+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfnull.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfnullfilled: org.apache.spark.sql.DataFrame = [International matches: string]\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfnullfilled  = dfnull.na.fill(avrg,Array(\"International matches\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|International matches|\n",
      "+---------------------+\n",
      "|                 null|\n",
      "|                   15|\n",
      "|                   11|\n",
      "|                   80|\n",
      "|                   67|\n",
      "|                 null|\n",
      "|                   40|\n",
      "|                   88|\n",
      "|                  116|\n",
      "|                   13|\n",
      "|                   23|\n",
      "|                   46|\n",
      "|                   64|\n",
      "|                   72|\n",
      "|                   10|\n",
      "|                   37|\n",
      "|                   16|\n",
      "|                   18|\n",
      "|                   86|\n",
      "|                   98|\n",
      "+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfnullfilled.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "2: error: not a legal formal parameter.",
     "output_type": "error",
     "traceback": [
      "<console>:2: error: not a legal formal parameter.",
      "Note: Tuples cannot be directly destructured in method or function parameters.",
      "      Either create a single parameter accepting the Tuple1,",
      "      or consider a pattern matching anonymous function: `{ case (param1, param1) => ... }",
      "       dfnull.select(dfnull.columns.map(\"International matches\" => {",
      "                                        ^",
      ""
     ]
    }
   ],
   "source": [
    "dfnull.select(dfnull.columns.map(\"International matches\" => {\n",
    "    count(when(col(\"International matches\").isNull, true)) as s\"${\"International matches\"}_nulls_count\"\n",
    "  }): _*)\n",
    "  .show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.col\n",
       "count: Long = 2\n"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.col\n",
    "val count = dfnull.filter(col(\"International matches\").isNull).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|International matches|\n",
      "+---------------------+\n",
      "|                 null|\n",
      "|                 null|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfnull.filter(isnull($\"International matches\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count_notnull: Long = 373\n"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val count_notnull = dfnull.filter(!isnull($\"International matches\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\n",
       "jsonStr: String = { \"metadata\": { \"key\": 84896, \"value\": 54 }}\n",
       "dfjson: org.apache.spark.sql.DataFrame = [metadata: struct<key: bigint, value: bigint>]\n"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "val jsonStr = \"\"\"{ \"metadata\": { \"key\": 84896, \"value\": 54 }}\"\"\"\n",
    "val dfjson = spark.read.json(Seq(jsonStr).toDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|   metadata|\n",
      "+-----------+\n",
      "|{84896, 54}|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfjson.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd: org.apache.spark.rdd.RDD[String] = /home/nagulraj/tact/scala/scala-basics/nagul/abc.txt MapPartitionsRDD[424] at textFile at <console>:49\n"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd = spark.sparkContext.textFile(\"/home/nagulraj/tact/scala/scala-basics/nagul/abc.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd2: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[425] at flatMap at <console>:50\n"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd2 = rdd.flatMap(f=>f.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd3: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[426] at map at <console>:50\n"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd3 = rdd2.map(m=>(m,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd4: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[427] at filter at <console>:50\n"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd4 = rdd3.filter(a=> a._1.startsWith(\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd5: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[428] at reduceByKey at <console>:50\n"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd5 = rdd4.reduceByKey(_ + _)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd6: org.apache.spark.rdd.RDD[(Int, String)] = ShuffledRDD[432] at sortByKey at <console>:50\n"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd6 = rdd5.map(a=>(a._2,a._1)).sortByKey()\n",
    "rdd6.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd5.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count : 4\n"
     ]
    }
   ],
   "source": [
    " println(\"Count : \"+rdd3.count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
